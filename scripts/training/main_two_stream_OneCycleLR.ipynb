{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"main_two_stream_OneCycleLR.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"MVIFMgSpaHAp"},"source":["# INSTALL MODULES\n","\n","%pip install pickle5\n","\n","# IMPORTS\n","import torch\n","from torch.utils.data import DataLoader\n","import torch.optim as optim\n","import numpy as np\n","import os\n","import pickle5 as pickle\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","\n","# Mount Google Drive in Colab\n","#from google.colab import files\n","from google.colab import drive\n","drive.mount(\"/content/gdrive\")\n","\n","# Import modules in Colab from other notebooks\n","%run '/content/gdrive/MyDrive/Colab Notebooks/dataset.ipynb'\n","%run '/content/gdrive/MyDrive/Colab Notebooks/models.ipynb'\n","\n","if not torch.cuda.is_available():\n","    raise RuntimeError(\"You should enable GPU runtime.\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"04uJB_r7aO8f"},"source":["# To speed up training, it's better to copy dataset from Drive to a Colab folder\n","\n","# choose a local (colab) directory to store the data.\n","local_dataset_path = os.path.expanduser('/content/data')\n","try:\n","  os.makedirs(local_dataset_path)\n","except: pass\n","\n","dataset_path = '/content/gdrive/MyDrive/jester_dataset'\n","\n","!cp -avr \"{dataset_path}\" \"{local_dataset_path}\"\n","\n","# Make sure it's there\n","!ls -lha /content/gdrive/MyDrive/jester_dataset/features"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1mnK_Q2PaeKR"},"source":["device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n","\n","# Retrieves features from i3d_resnet50_v1_kinetics400 Gluon pre-trained model extracted from our 9 classes' Jester dataset videos\n","with open('/content/data/jester_dataset/features/features_RGB.pickle', 'rb') as handle:\n","    rgb_dict = pickle.load(handle)        # dict as {n_video:features, ...}  features: (1,2048)\n","with open('/content/data/jester_dataset/features/features_flow.pickle', 'rb') as handle:\n","    flow_dict = pickle.load(handle)        # dict as {n_video:features, ...}  features: (1,2048)\n","    \n","csv_dir = '/content/data/jester_dataset/csv/'  # if in Google Cloud --> csv_dir = '/mnt/disks/disk-1/jester_dataset/dataset/csvs/' \n","train_csv = csv_dir + 'train.csv' \n","val_csv = csv_dir + 'validation.csv'\n","labels = csv_dir + 'labels.csv'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ASjka972a7sF"},"source":["def train_epoch(model, train_loader, optimizer, scheduler, criterion):  # Modified for OneCycleLR (added scheduler)\n","  model.train()\n","  accs, losses = [], []\n","  for rgb, flow, labels in train_loader:\n","    optimizer.zero_grad()\n","    rgb, flow, labels = rgb.to(device), flow.to(device), labels.to(device)\n","    output = model(rgb, flow)\n","    loss = criterion(output, labels)\n","    loss.backward()\n","    optimizer.step()\n","    scheduler.step()                                            # Added for OneCycleLR\n","    accs.append(accuracy(labels, output))\n","    losses.append(loss.item())\n","  return np.mean(losses), np.mean(accs)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-ibZPAQlbKoK"},"source":["def eval_epoch(model, val_loader, criterion): \n","  with torch.no_grad():\n","    model.eval()\n","    accs, losses = [], []\n","    for rgb, flow, labels in val_loader:\n","      rgb, flow, labels = rgb.to(device), flow.to(device), labels.to(device)\n","      output = model(rgb, flow)\n","      loss = criterion(output, labels)\n","      accs.append(accuracy(labels, output))\n","      losses.append(loss.item())\n","    return np.mean(losses), np.mean(accs)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oYH3Ff95bXBS"},"source":["def accuracy(labels, outputs):\n","    preds = outputs.argmax(-1)\n","    acc = (preds == labels.view_as(preds)).cpu().float().detach().numpy().mean()\n","    return acc"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ufiLGJLHbaSN"},"source":["def train_model(config):\n","  # DATASETS\n","  train_dataset = JesterDatasetTwoStream(rgb_dict, flow_dict, train_csv, labels)\n","  validation_dataset = JesterDatasetTwoStream(rgb_dict, flow_dict, val_csv, labels)\n","\n","  train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True)\n","  validation_loader = DataLoader(validation_dataset, batch_size=config['batch_size'], shuffle=False)\n","\n","  # MODEL\n","  model = ClassifierTwoStreamAfter(h_rgb=config['hidden_rgb'], h_flow=config['hidden_flow'], dropout=config['dropout']).to(device)\n","  optimizer = optim.Adam(model.parameters(), lr = config['lr'])\n","  #optimizer = optim.SGD(model.parameters(), lr=config['lr'], momentum=0.9)\n","  scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.01, steps_per_epoch=len(train_loader), epochs=config['epochs']) # Added for OneCycleLR\n","\n","  counts = pd.read_csv(train_csv).Action.value_counts()       # Counts = list of video counts for each class\n","  weights = torch.tensor([max(counts)/x for x in counts])     # calculates weights for all classes in training dataset (weight regularization)\n","  criterion = nn.CrossEntropyLoss(weight=weights).to(device)  # assigns weight to each of the classes. This is particularly useful when you have an unbalanced training set\n","  \n","  train_losses, val_losses, train_accs, val_accs = [], [], [], []\n","\n","  for epoch in range(config['epochs']):\n","    \n","    loss, acc = train_epoch(model, train_loader, optimizer, scheduler, criterion) # Modified for OneCycleLR (added scheduler)\n","    train_losses.append(loss)\n","    train_accs.append(acc)\n","    print(f\"Train Epoch {epoch+1} loss={loss:.2f} acc={acc:.2f}\")\n","    \n","    loss, acc = eval_epoch(model, validation_loader, criterion)\n","    val_losses.append(loss)\n","    val_accs.append(acc)\n","    print(f\"Eval Epoch {epoch+1} loss={loss:.2f} acc={acc:.2f}\")\n","\n","  # Saves the model_state_dict to load it later in the final system's model to do inference \n","  savedir = '/content/gdrive/MyDrive/model/state_dict.pt'\n","  print(f\"Saving checkpoint to {savedir}...\")\n","  checkpoint = {\n","      \"model_state_dict\": model.cpu().state_dict(),\n","  }\n","  torch.save(checkpoint, savedir)\n","  \n","  return model, [train_losses, train_accs, val_losses, val_accs]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Sou9J7sp3FJD"},"source":["if __name__ == \"__main__\":\n","\n","    config = {\n","            \"lr\": 0.000178044,\n","            \"batch_size\": 64,\n","            \"hidden_rgb\": 1024,\n","            \"hidden_flow\": 1024,\n","            \"dropout\": 0.8,\n","            \"epochs\": 100,\n","    }\n","\n","    trained_model, metrics = train_model(config)\n","\n","    print(\"Training finished\")\n","    \n","    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IsQVSmXAb9fJ"},"source":["fig = plt.figure(figsize=[14,5])\n","plt.subplot(1, 2, 1)\n","plt.plot(metrics[0],label='Train')\n","plt.plot(metrics[2],label='Val')\n","plt.legend(fontsize=12)\n","plt.title('Loss',fontsize=16)\n","plt.grid()\n","plt.xlabel('Epoch',fontsize=12)\n","plt.ylabel('Loss',fontsize=12)\n","plt.subplot(1, 2, 2)\n","plt.plot(metrics[1],label='Train')\n","plt.plot(metrics[3],label='Val')\n","plt.title('Accuracy',fontsize=16)\n","plt.legend(fontsize=12)\n","plt.grid()\n","plt.xlabel('Epoch',fontsize=12)\n","plt.ylabel('Accuracy',fontsize=12)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rEPwxAZQcAJT"},"source":["import seaborn as sns\n","validation_dataset = JesterDatasetTwoStream(rgb_dict, flow_dict, val_csv, labels)\n","\n"," \n","validation_loader = DataLoader(validation_dataset, batch_size=config['batch_size'], shuffle=False)\n","nb_classes = 9\n","confusion_matrix = np.zeros((nb_classes, nb_classes))\n","trained_model = trained_model.to(device)\n","with torch.no_grad():\n","    for i, (rgb, flow, classes) in enumerate(validation_loader):\n","        rgb = rgb.to(device)\n","        flow = flow.to(device)\n","        classes = classes.to(device)\n","        outputs = trained_model(rgb, flow)\n","        _, preds = torch.max(outputs, 1)\n","        for t, p in zip(classes.view(-1), preds.view(-1)):\n","                confusion_matrix[t.long(), p.long()] += 1\n","\n","plt.figure(figsize=(12,7))\n","\n","l = pd.read_csv(labels)\n","class_names = list(l['Actions'])\n","l['Accuracy'] = np.diag(confusion_matrix)/confusion_matrix.sum(1)\n","df_cm = pd.DataFrame(confusion_matrix, index=class_names, columns=class_names).astype(int)\n","heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n","\n","heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right',fontsize=12)\n","heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right',fontsize=12)\n","plt.ylabel('True label')\n","plt.xlabel('Predicted label')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MAJxwfufE2n_"},"source":["l"],"execution_count":null,"outputs":[]}]}