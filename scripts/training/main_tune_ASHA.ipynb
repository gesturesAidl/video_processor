{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"main_tune_ASHA.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"xyZ5z0XEx-a7"},"source":["# INSTALL MODULES\n","%pip install pickle5\n","\n","# For ray.Tune\n","%pip install ray torch torchvision      # Preferred install command when running PyTorch\n","#%pip install -U ray                    # Alternate installation for Tune\n","\n","# For Tensorboard\n","%pip install tensorboardX\n","\n","# IMPORTS\n","import torch\n","from torch.utils.data import DataLoader\n","import torch.optim as optim\n","import numpy as np\n","import os\n","import pickle5 as pickle\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","from ray import tune\n","from ray.tune.schedulers import ASHAScheduler           # To use ASHA Scheduler (it's recommended using this over the standard HyperBand scheduler)\n","import tensorboardX\n","\n","# Load the TensorBoard notebook extension\n","%load_ext tensorboard\n","\n","# Mount Google Drive in Colab\n","#from google.colab import files\n","from google.colab import drive\n","drive.mount(\"/content/gdrive\")\n","\n","# Import modules in Colab from another notebooks\n","%run '/content/gdrive/MyDrive/Colab Notebooks/training/dataset.ipynb'\n","%run '/content/gdrive/MyDrive/Colab Notebooks/training/models.ipynb'\n","\n","if not torch.cuda.is_available():\n","    raise RuntimeError(\"You should enable GPU runtime.\")\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DkV1MMvJ8K8A","executionInfo":{"status":"ok","timestamp":1615635579354,"user_tz":-60,"elapsed":66367,"user":{"displayName":"Gestures Aidl","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmUL-j7pf6ANBc5oAoXRe-bANO1KAMQ4Yzy76P=s64","userId":"03015692303882784291"}},"outputId":"68883f31-0831-44e7-c466-671f4d1a4887"},"source":["# To speed up training, it's better to copy dataset from Drive to a Colab folder\n","\n","# choose a local (colab) directory to store the data.\n","local_dataset_path = os.path.expanduser('/content/data')\n","try:\n","  os.makedirs(local_dataset_path)\n","except: pass\n","\n","dataset_path = '/content/gdrive/MyDrive/jester_dataset/'\n","\n","!cp -avr \"{dataset_path}\" \"{local_dataset_path}\"\n","\n","# Make sure it's there\n","!ls -lha /content/gdrive/MyDrive/jester_dataset/features"],"execution_count":null,"outputs":[{"output_type":"stream","text":["'/content/gdrive/MyDrive/jester_dataset/' -> '/content/data/jester_dataset'\n","'/content/gdrive/MyDrive/jester_dataset/features' -> '/content/data/jester_dataset/features'\n","'/content/gdrive/MyDrive/jester_dataset/features/features_flow.pickle' -> '/content/data/jester_dataset/features/features_flow.pickle'\n","'/content/gdrive/MyDrive/jester_dataset/features/features_RGB.pickle' -> '/content/data/jester_dataset/features/features_RGB.pickle'\n","'/content/gdrive/MyDrive/jester_dataset/csv' -> '/content/data/jester_dataset/csv'\n","'/content/gdrive/MyDrive/jester_dataset/csv/validation.csv' -> '/content/data/jester_dataset/csv/validation.csv'\n","'/content/gdrive/MyDrive/jester_dataset/csv/train.csv' -> '/content/data/jester_dataset/csv/train.csv'\n","'/content/gdrive/MyDrive/jester_dataset/csv/labels.csv' -> '/content/data/jester_dataset/csv/labels.csv'\n","'/content/gdrive/MyDrive/jester_dataset/csv/train.gsheet' -> '/content/data/jester_dataset/csv/train.gsheet'\n","cp: cannot open '/content/gdrive/MyDrive/jester_dataset/csv/train.gsheet' for reading: Operation not supported\n","'/content/gdrive/MyDrive/jester_dataset/csv/validation.gsheet' -> '/content/data/jester_dataset/csv/validation.gsheet'\n","cp: cannot open '/content/gdrive/MyDrive/jester_dataset/csv/validation.gsheet' for reading: Operation not supported\n","'/content/gdrive/MyDrive/jester_dataset/no_train.npy' -> '/content/data/jester_dataset/no_train.npy'\n","'/content/gdrive/MyDrive/jester_dataset/no_val.npy' -> '/content/data/jester_dataset/no_val.npy'\n","'/content/gdrive/MyDrive/jester_dataset/missing_videos_copy.log' -> '/content/data/jester_dataset/missing_videos_copy.log'\n","'/content/gdrive/MyDrive/jester_dataset/Jester dataset.xlsx' -> '/content/data/jester_dataset/Jester dataset.xlsx'\n","total 756M\n","-rw------- 1 root root 378M Mar  9 23:06 features_flow.pickle\n","-rw------- 1 root root 378M Mar 10 16:29 features_RGB.pickle\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rxBa45SoyJmh"},"source":["device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n","\n","# Retrieves features from i3d_resnet50_v1_kinetics400 Gluon pre-trained model extracted from our 9 classes' Jester dataset videos\n","with open('/content/data/jester_dataset/features/features_RGB.pickle', 'rb') as handle:\n","    features_dict = pickle.load(handle)        # dict as {n_video:features, ...}  features: (1,2048)\n","    \n","csv_dir = '/content/data/jester_dataset/csv/'  # if in Google Cloud --> csv_dir = '/mnt/disks/disk-1/jester_dataset/dataset/csvs/' \n","train_csv = csv_dir + 'train.csv' \n","val_csv = csv_dir + 'validation.csv'\n","labels = csv_dir + 'labels.csv'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fxAIWu2XyY6W"},"source":["def train_epoch(model, train_loader, optimizer, criterion, epoch):  \n","  model.train()\n","  accs, losses = [], []\n","\n","  for features, labels in train_loader:\n","    optimizer.zero_grad()\n","    features, labels = features.to(device), labels.to(device)\n","    output = model(features)\n","    loss = criterion(output, labels)\n","    loss.backward()\n","    optimizer.step()\n","    accs.append(accuracy(labels, output))\n","    losses.append(loss.item())\n","\n","  return np.mean(losses), np.mean(accs)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hJ16o7Ru0mpZ"},"source":["def eval_epoch(model, val_loader, criterion, epoch): \n","  with torch.no_grad():\n","    model.eval()\n","    accs, losses = [], []\n","\n","    for features, labels in val_loader:\n","      features, labels = features.to(device), labels.to(device)\n","      output = model(features)\n","      loss = criterion(output, labels)\n","      accs.append(accuracy(labels, output))\n","      losses.append(loss.item())\n","\n","    return np.mean(losses), np.mean(accs)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KqehVqBp0ivg"},"source":["def accuracy(labels, outputs):\n","    preds = outputs.argmax(-1)\n","    acc = (preds == labels.view_as(preds)).cpu().float().detach().numpy().mean()\n","    return acc"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kI7nBvH21bc3"},"source":["def train_model(config):\n","  # DATASETS\n","  train_dataset = JesterDatasetOneStream(features_dict, train_csv, labels)\n","  validation_dataset = JesterDatasetOneStream(features_dict, val_csv, labels)\n","\n","  train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True)\n","  validation_loader = DataLoader(validation_dataset, batch_size=config['batch_size'], shuffle=False)\n","\n","  # MODEL\n","  model = ClassifierOneStream(hidden_sz=config['hidden_size'], dropout=config['dropout']).to(device)\n","  optimizer = optim.Adam(model.parameters(), lr = config['lr'])\n","\n","  counts = pd.read_csv(train_csv).Action.value_counts()       # Counts = list of video counts for each class\n","  weights = torch.tensor([max(counts)/x for x in counts])     # calculates weights for all classes in training dataset (weight regularization)\n","  criterion = nn.CrossEntropyLoss(weight=weights).to(device)  # assigns weight to each of the classes. This is particularly useful when you have an unbalanced training set\n","  \n","  train_losses = []\n","  val_losses = []\n","  train_accs = []\n","  val_accs = []\n","  \n","  for epoch in range(config['epochs']+1):\n","    \n","    loss, acc = train_epoch(model, train_loader, optimizer, criterion, epoch)\n","    train_losses.append(loss)\n","    train_accs.append(acc)\n","    print(f\"Train Epoch {epoch} loss={loss:.2f} acc={acc:.2f}\")\n","        \n","    loss, acc = eval_epoch(model, validation_loader, criterion, epoch)\n","    val_losses.append(loss)\n","    val_accs.append(acc)\n","    print(f\"Eval Epoch {epoch} loss={loss:.2f} acc={acc:.2f}\")\n","    tune.report(tune_loss=loss, accuracy=acc)       # send report to Tune\n","\n","     "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Sou9J7sp3FJD"},"source":["if __name__ == \"__main__\":\n","\n","    config = {\n","            \"lr\": tune.loguniform(1e-4, 1e-2),\n","            \"batch_size\": tune.choice([8, 16, 32, 64, 128, 256]),\n","            \"hidden_size\": tune.sample_from(lambda _: 2**np.random.randint(7, 12)),      # 128, 256, 512, 1024 or 2048\n","            \"dropout\": 0.5,\n","            \"epochs\": 20,\n","            }\n","\n","    asha_scheduler = ASHAScheduler(             # For using ASHA (AsyncHyperBandScheduler) (recommended over Hyperband optimization)\n","            time_attr='epoch',\n","            max_t=config[\"epochs\"],\n","            grace_period=1,\n","            reduction_factor=2,\n","            )\n","\n","    analysis = tune.run(                        # run hyperparameter tuning trials with Tune\n","        train_model,\n","        metric=\"tune_loss\",\n","        mode=\"min\",\n","        num_samples=50,\n","        resources_per_trial= {\n","            #\"cpu\": 1,\n","            \"gpu\": 1  # set this for GPUs\n","        },\n","        config = config,\n","        scheduler=asha_scheduler,\n","        local_dir='/content/gdrive/MyDrive/ray_results/'\n","        )\n","\n","    print(\"Best hyperparameters found were: \", analysis.best_config)\n","\n","    best_trial = analysis.get_best_trial(\"tune_loss\", \"min\", \"last\")\n","    print(\"\\nBest trial config: {}\".format(best_trial.config))\n","    print(\"Best trial final validation loss: {}\".format(\n","        best_trial.last_result[\"tune_loss\"]))\n","    print(\"Best trial final validation accuracy: {}\".format(\n","        best_trial.last_result[\"accuracy\"]))\n","    \n","    print(\"\\nHyperparameter tuning finished\")\n","    \n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"09rnnFgaOvhY"},"source":["%tensorboard --logdir ~/ray_results"],"execution_count":null,"outputs":[]}]}